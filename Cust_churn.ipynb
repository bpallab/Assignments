{"cells":[{"cell_type":"markdown","source":["# Problem Statement\nA marketing agency has many customers that use their service to produce ads for the\nclient/customer websites. They've noticed that they have quite a bit of churn in clients. They basically\nrandomly assign account managers right now, but want you to create a machine learning model that\nwill help predict which customers will churn (stop buying their service) so that they can correctly\nassign the customers most at risk to churn an account manager. Luckily they have some historical\ndata, can you help them out? Create a classification algorithm that will help classify whether or not a\ncustomer churned. Then the company can test this against incoming data for future customers to\npredict which customers will churn and assign them an account manager."],"metadata":{}},{"cell_type":"markdown","source":["## Solution\n We will create a model using **Logistic Regression** on given data and apply it on new dataset."],"metadata":{}},{"cell_type":"code","source":["from pyspark.sql import SparkSession"],"metadata":{},"outputs":[],"execution_count":3},{"cell_type":"code","source":["spark = SparkSession.builder.appName('churn').getOrCreate()"],"metadata":{},"outputs":[],"execution_count":4},{"cell_type":"code","source":["# Load data as spark dataframe\ndata = spark.read.table('churn')"],"metadata":{},"outputs":[],"execution_count":5},{"cell_type":"code","source":["data.printSchema()"],"metadata":{},"outputs":[],"execution_count":6},{"cell_type":"code","source":["from pyspark.ml.feature import (VectorAssembler,VectorIndexer,\n                                OneHotEncoder,StringIndexer)"],"metadata":{},"outputs":[],"execution_count":7},{"cell_type":"code","source":["data.groupBy('Company').count().show()"],"metadata":{},"outputs":[],"execution_count":8},{"cell_type":"code","source":["data.columns"],"metadata":{},"outputs":[],"execution_count":9},{"cell_type":"markdown","source":["We are ignoring **Name**, **Company**, **Onboard_date** and **Location** column. As they are hardly provinding any information and mostly values are unique."],"metadata":{}},{"cell_type":"code","source":["#Create a feature vector\nassembler = VectorAssembler(inputCols=[\n 'Age',\n 'Total_Purchase',\n 'Account_Manager',\n 'Years',\n 'Num_Sites'],outputCol='features')"],"metadata":{},"outputs":[],"execution_count":11},{"cell_type":"code","source":["output = assembler.transform(data)"],"metadata":{},"outputs":[],"execution_count":12},{"cell_type":"code","source":["from pyspark.ml.classification import LogisticRegression"],"metadata":{},"outputs":[],"execution_count":13},{"cell_type":"code","source":["#Even if target variable is already binary, performing this step to maintain consistency and practice  \nindexer = StringIndexer(inputCol=\"Churn\", outputCol=\"ChurnIndexed\")\noutput_fixed = indexer.fit(output).transform(output)"],"metadata":{},"outputs":[],"execution_count":14},{"cell_type":"code","source":["log_reg = LogisticRegression(featuresCol='features',labelCol='ChurnIndexed', maxIter=500) "],"metadata":{},"outputs":[],"execution_count":15},{"cell_type":"code","source":["final_data = output_fixed.select(\"features\",'ChurnIndexed')"],"metadata":{},"outputs":[],"execution_count":16},{"cell_type":"code","source":["#splitting the data into train and test \ntrain_data, test_data = final_data.randomSplit([0.8,.2])"],"metadata":{},"outputs":[],"execution_count":17},{"cell_type":"code","source":["model = log_reg.fit(train_data)"],"metadata":{},"outputs":[],"execution_count":18},{"cell_type":"code","source":["results = model.transform(test_data)"],"metadata":{},"outputs":[],"execution_count":19},{"cell_type":"code","source":["#Evaluating the result \nfrom pyspark.ml.evaluation import BinaryClassificationEvaluator\nmy_eval = BinaryClassificationEvaluator(rawPredictionCol='prediction',\n                                       labelCol='ChurnIndexed')\n"],"metadata":{},"outputs":[],"execution_count":20},{"cell_type":"code","source":["results.select('ChurnIndexed','prediction').show()"],"metadata":{},"outputs":[],"execution_count":21},{"cell_type":"code","source":["AUC = my_eval.evaluate(results)"],"metadata":{},"outputs":[],"execution_count":22},{"cell_type":"code","source":["AUC"],"metadata":{},"outputs":[],"execution_count":23},{"cell_type":"markdown","source":["We have achieved 78% accuracy on given data."],"metadata":{}},{"cell_type":"markdown","source":["### Now Let's check how our model performs on new data"],"metadata":{}},{"cell_type":"code","source":["test_data1 = spark.read.table('newdata')"],"metadata":{},"outputs":[],"execution_count":26},{"cell_type":"code","source":["test_data2=assembler.transform(test_data1)"],"metadata":{},"outputs":[],"execution_count":27},{"cell_type":"code","source":["results1 = model.transform(test_data2)"],"metadata":{},"outputs":[],"execution_count":28},{"cell_type":"code","source":["new_eval = BinaryClassificationEvaluator(rawPredictionCol='prediction')"],"metadata":{},"outputs":[],"execution_count":29},{"cell_type":"code","source":["results1.select('prediction').show()"],"metadata":{},"outputs":[],"execution_count":30},{"cell_type":"markdown","source":["We do not have taget variable to evaluate our result for new data."],"metadata":{}}],"metadata":{"name":"Cust_churn","notebookId":3018809056090950},"nbformat":4,"nbformat_minor":0}

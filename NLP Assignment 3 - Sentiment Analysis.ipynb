{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis using NLTK Part-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The goal here is to predict the sentiments behind movie reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from random import shuffle\n",
    "from nltk.corpus import movie_reviews as mr\n",
    "from nltk.corpus import sentiwordnet as swn\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will convert the **CategorizedPlaintextCorpusReader** data into **python list**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reviews = []\n",
    "for fileid in mr.fileids():\n",
    "    tag, filename = fileid.split('/')\n",
    "    reviews.append([mr.raw(fileid), tag])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(reviews)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our dataset first 1000 reviews are negative and later are positives. So we will shuffle the data using **shuffle**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "shuffle(reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tom dicillo directs this superficial comedy about superficial people in superficial careers , all searching for deeper meaning . \\nhowever , they won\\'t find much meaning in the real blonde , and not enough real humor , either . \\njoe ( matthew modine ) is a struggling actor , or he claims to be one , even though he has no credits under his belt . \\nhis girlfriend , mary ( catherine keener ) has no pretensions about her career : she\\'s a makeup artist , working for the eccentric fashion photographer blair ( marlo thomas ) and supermodel of the month , sahara ( bridgette wilson ) . \\nsahara , who has acquired a new age spirituality from repeated viewing of the little mermaid , has an on-again , off-again relationship with joe\\'s best friend , bob ( maxwell caulfield ) . \\nhowever , bob has gotten his biggest break yet : a starring role on a soap opera opposite the beautiful kelly ( daryl hannah ) , who may be that illusive woman he\\'s always pursued : a real blonde . \\nthere are some moments of good humor in the real blonde , but not enough . \\nthe best stuff is in throwaway details in the background , such as sahara\\'s perfume ads : \" depression - it\\'s not just a state of mind \" . \\nbut to find humor in the superficiality of models and actors is to shoot fish in a barrel . \\nand , unfortunately , the film\\'s forays outside the realm of comedy are pathetic . \\ntake for example the film\\'s framing device of an old lady and her dog . \\nthe story serves absolutely no purpose , makes little sense , and is completely tangential to the main plotlines of the movie . \\nmatthew modine and catherine keener have the most sympathetic characters in the film , but they\\'re stuck in the most boring plotlines . \\nmodine whines and complains and would be completely pathetic if he was matched against someone stronger than elizabeth berkley , who appears as another struggling actor . \\nkeener\\'s character has a stronger edge , but the insult self-defense class ( taught by denis leary , no less ) she is stuck in makes little sense . \\nthe movie\\'s running time is under two hours , but it seems like it is well over it . \\nthere\\'s just not enough humor to speed things along , and not enough meaning to propel any drama . \\n',\n",
       " 'neg']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews[1768]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we divide the dataset into train and test. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train=reviews[:1500]\n",
    "test=reviews[1500:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will create a vocabulary for each review and use it to get unigram features from the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44646\n"
     ]
    }
   ],
   "source": [
    "#Required for Bag of words (unigram features) creation\n",
    "vocabulary = [x.lower() for tagged_sent in train for x in tagged_sent[0].split()]\n",
    "vocabulary = list(set(vocabulary))\n",
    "vocabulary.sort() #sorting the list\n",
    "print(len(vocabulary))\n",
    "#print(vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_unigram_features(data,vocab):\n",
    "    fet_vec_all = []\n",
    "    for tup in data:\n",
    "        single_feat_vec = []\n",
    "        sent = tup[0].lower() #lowercasing the dataset\n",
    "        for v in vocab:\n",
    "            if sent.__contains__(v):\n",
    "                single_feat_vec.append(1)\n",
    "            else:\n",
    "                single_feat_vec.append(0)\n",
    "        fet_vec_all.append(single_feat_vec)\n",
    "    return fet_vec_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_senti_wordnet_features(data):\n",
    "    fet_vec_all = []\n",
    "    for tup in data:\n",
    "        sent = tup[0].lower()\n",
    "        words = sent.split()\n",
    "        pos_score = 0\n",
    "        neg_score = 0\n",
    "        for w in words:\n",
    "            senti_synsets = swn.senti_synsets(w.lower())\n",
    "            for senti_synset in senti_synsets:\n",
    "                p = senti_synset.pos_score()\n",
    "                n = senti_synset.neg_score()\n",
    "                pos_score+=p\n",
    "                neg_score+=n\n",
    "                break #take only the first synset (Most frequent sense)\n",
    "        fet_vec_all.append([float(pos_score),float(neg_score)])\n",
    "    return fet_vec_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def merge_features(featureList1,featureList2):\n",
    "    # For merging two features\n",
    "    if featureList1==[]:\n",
    "        return featureList2\n",
    "    merged = []\n",
    "    for i in range(len(featureList1)):\n",
    "        m = featureList1[i]+featureList2[i]\n",
    "        merged.append(m)\n",
    "    return merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_lables(data):\n",
    "    labels = []\n",
    "    for tup in data:\n",
    "        if tup[1].lower()==\"neg\":\n",
    "            labels.append(-1)\n",
    "        else:\n",
    "            labels.append(1)\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_precision(prediction, actual):\n",
    "    prediction = list(prediction)\n",
    "    correct_labels = [predictions[i]  for i in range(len(predictions)) if actual[i] == predictions[i]]\n",
    "    precision = float(len(correct_labels))/float(len(prediction))\n",
    "    return precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def real_time_test(classifier,vocab):\n",
    "    print(\"Enter a sentence: \")\n",
    "    inp = input()\n",
    "    feat_vec_uni = get_unigram_features(inp,vocab)\n",
    "    feat_vec_swn =get_senti_wordnet_features(test_data)\n",
    "    feat_vec = merge_features(feat_vec_uni, feat_vec_swn)\n",
    "\n",
    "    predict = classifier.predict(feat_vec)\n",
    "    if predict[0]==1:\n",
    "        print(\"The sentiment expressed is: positive\")\n",
    "    else:\n",
    "        print(\"The sentiment expressed is: negative\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_features = get_unigram_features(train,vocabulary) # vocabulary extracted in the beginning\n",
    "training_labels = get_lables(train)\n",
    "\n",
    "test_features = get_unigram_features(test,vocabulary)\n",
    "test_gold_labels = get_lables(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training_features[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision of NB classifier is\n",
      "Training data\t0.9946666666666667\n",
      "Test data\t0.8\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "nb_classifier = MultinomialNB(alpha=0.1).fit(training_features,training_labels) #training process\n",
    "\n",
    "print(\"Precision of NB classifier is\")\n",
    "predictions = nb_classifier.predict(training_features)\n",
    "precision = calculate_precision(predictions,training_labels)\n",
    "print(\"Training data\\t\" + str(precision))\n",
    "predictions = nb_classifier.predict(test_features)\n",
    "precision = calculate_precision(predictions,test_gold_labels)\n",
    "print(\"Test data\\t\" + str(precision))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision of SVM classifier is\n",
      "Training data\t0.5066666666666667\n",
      "Test data\t0.48\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "clf = SVC(C=0.01, kernel='sigmoid').fit(training_features,training_labels)\n",
    "print(\"Precision of SVM classifier is\")\n",
    "predictions = clf.predict(training_features)\n",
    "precision = calculate_precision(predictions,training_labels)\n",
    "print(\"Training data\\t\" + str(precision))\n",
    "predictions = clf.predict(test_features)\n",
    "precision = calculate_precision(predictions,test_gold_labels)\n",
    "print(\"Test data\\t\" + str(precision))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision of Decision Tree classifier is\n",
      "Training data\t0.64\n",
      "Test data\t0.574\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "clf = DecisionTreeClassifier(max_depth=5, max_features='sqrt', random_state=42).fit(training_features,training_labels)\n",
    "print(\"Precision of Decision Tree classifier is\")\n",
    "predictions = clf.predict(training_features)\n",
    "precision = calculate_precision(predictions,training_labels)\n",
    "print(\"Training data\\t\" + str(precision))\n",
    "predictions = clf.predict(test_features)\n",
    "precision = calculate_precision(predictions,test_gold_labels)\n",
    "print(\"Test data\\t\" + str(precision))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision of Logistic Regression is\n",
      "Training data\t1.0\n",
      "Test data\t0.846\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression(random_state=42).fit(training_features,training_labels)\n",
    "print(\"Precision of Logistic Regression is\")\n",
    "predictions = clf.predict(training_features)\n",
    "precision = calculate_precision(predictions,training_labels)\n",
    "print(\"Training data\\t\" + str(precision))\n",
    "predictions = clf.predict(test_features)\n",
    "precision = calculate_precision(predictions,test_gold_labels)\n",
    "print(\"Test data\\t\" + str(precision))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis using NLTK Part-2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The goal here is to predict the sentiments behind tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import twitter_samples as ts\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "mypath= 'C:/Users/Sociopath/AppData/Roaming/nltk_data/corpora/twitter_samples/'\n",
    "pos = []\n",
    "for line in open (mypath + r'positive_tweets.json', 'r'):\n",
    "    pos.append(json.loads(line))\n",
    "\n",
    "neg = []\n",
    "for line in open (mypath + r'negative_tweets.json', 'r'):\n",
    "    neg.append(json.loads(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#colname = [\"created_at\", \"favorite_count\", \"retweet_count\", \"id\", \"place\", \"coordinates\", \"geo\", \"text\"]\n",
    "\n",
    "df0 = []\n",
    "for dic in pos:\n",
    "    ll = []\n",
    "    ll.append(dic['text'])\n",
    "    ll.append(\"pos\")\n",
    "    df0.append(ll)\n",
    "\n",
    "df1 = []\n",
    "for dic in neg:\n",
    "    ll = []\n",
    "    ll.append(dic['text'])\n",
    "    ll.append(\"neg\")\n",
    "    df1.append(ll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "df0.extend(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=df0\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "shuffle(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=df[:7000]\n",
    "test=df[7000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19642\n"
     ]
    }
   ],
   "source": [
    "#Required for Bag of words (unigram features) creation\n",
    "vocabulary = [x.lower() for tagged_sent in train for x in tagged_sent[0].split()]\n",
    "vocabulary = list(set(vocabulary))\n",
    "vocabulary.sort() #sorting the list\n",
    "print(len(vocabulary))\n",
    "#print(vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_features = get_unigram_features(train,vocabulary) # vocabulary extracted in the beginning\n",
    "training_labels = get_lables(train)\n",
    "\n",
    "test_features = get_unigram_features(test,vocabulary)\n",
    "test_gold_labels = get_lables(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision of NB classifier is\n",
      "Training data\t0.9997142857142857\n",
      "Test data\t0.9893333333333333\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "nb_classifier = MultinomialNB(alpha=0.1).fit(training_features,training_labels) #training process\n",
    "\n",
    "print(\"Precision of NB classifier is\")\n",
    "predictions = nb_classifier.predict(training_features)\n",
    "precision = calculate_precision(predictions,training_labels)\n",
    "print(\"Training data\\t\" + str(precision))\n",
    "predictions = nb_classifier.predict(test_features)\n",
    "precision = calculate_precision(predictions,test_gold_labels)\n",
    "print(\"Test data\\t\" + str(precision))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision of SVM classifier is\n",
      "Training data\t0.5007142857142857\n",
      "Test data\t0.49833333333333335\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "clf = SVC(C=0.01, kernel='sigmoid').fit(training_features,training_labels)\n",
    "print(\"Precision of SVM classifier is\")\n",
    "predictions = clf.predict(training_features)\n",
    "precision = calculate_precision(predictions,training_labels)\n",
    "print(\"Training data\\t\" + str(precision))\n",
    "predictions = clf.predict(test_features)\n",
    "precision = calculate_precision(predictions,test_gold_labels)\n",
    "print(\"Test data\\t\" + str(precision))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision of Decision Tree classifier is\n",
      "Training data\t0.5511428571428572\n",
      "Test data\t0.5616666666666666\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "clf = DecisionTreeClassifier(max_depth=5, max_features='sqrt', random_state=42).fit(training_features,training_labels)\n",
    "print(\"Precision of Decision Tree classifier is\")\n",
    "predictions = clf.predict(training_features)\n",
    "precision = calculate_precision(predictions,training_labels)\n",
    "print(\"Training data\\t\" + str(precision))\n",
    "predictions = clf.predict(test_features)\n",
    "precision = calculate_precision(predictions,test_gold_labels)\n",
    "print(\"Test data\\t\" + str(precision))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression(random_state=42).fit(training_features,training_labels)\n",
    "print(\"Precision of Logistic Regression is\")\n",
    "predictions = clf.predict(training_features)\n",
    "precision = calculate_precision(predictions,training_labels)\n",
    "print(\"Training data\\t\" + str(precision))\n",
    "predictions = clf.predict(test_features)\n",
    "precision = calculate_precision(predictions,test_gold_labels)\n",
    "print(\"Test data\\t\" + str(precision))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('''\n",
    "(Dataset)        (Naive Bayes)    (SVM)   (Decision-tree)   (Logistic-Regression) \n",
    "\n",
    "movie_review        {}              {}          {}               {}\n",
    "\n",
    "twitter_dataset     {}              {}          {}               {}\n",
    "\n",
    "'''*.format())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
